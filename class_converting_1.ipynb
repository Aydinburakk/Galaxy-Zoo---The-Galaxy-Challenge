{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "klasor_yolu = 'img_train/' \n",
    "dosya_isimleri = [dosya for dosya in os.listdir(klasor_yolu) if dosya.endswith('.jpg')]\n",
    "\n",
    "hedef_boyut = (106, 106)\n",
    "\n",
    "data = []\n",
    "for dosya in dosya_isimleri:\n",
    "    tam_yol = os.path.join(klasor_yolu, dosya)\n",
    "    with Image.open(tam_yol) as img:\n",
    "        img = img.convert('L').resize(hedef_boyut)  \n",
    "        numpy_dizi = np.array(img).flatten()  \n",
    "        data.append(numpy_dizi)\n",
    "\n",
    "sonuc_matrisi = np.vstack(data)\n",
    "\n",
    "csv_dosya_yolu = 'train_sol.csv' \n",
    "csv_matrisi = pd.read_csv(csv_dosya_yolu).values\n",
    "\n",
    "csv_matrisi = csv_matrisi[:, 1:]\n",
    "\n",
    "data_train = np.hstack((sonuc_matrisi/255, csv_matrisi)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 12316 and the array at index 1 has size 49262",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m csv_matrisi \u001b[38;5;241m=\u001b[39m csv_matrisi[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Fotoğraf matrisi ile CSV matrisini birleştir\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m data_test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msonuc_matrisi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_matrisi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# son 36 çıktılar\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\burak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py:370\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 12316 and the array at index 1 has size 49262"
     ]
    }
   ],
   "source": [
    "klasor_yolu = 'img_test/'  \n",
    "dosya_isimleri = [dosya for dosya in os.listdir(klasor_yolu) if dosya.endswith('.jpg')]\n",
    "\n",
    "hedef_boyut = (106, 106)\n",
    "\n",
    "data = []\n",
    "for dosya in dosya_isimleri:\n",
    "    tam_yol = os.path.join(klasor_yolu, dosya)\n",
    "    with Image.open(tam_yol) as img:\n",
    "        img = img.convert('L').resize(hedef_boyut)  \n",
    "        numpy_dizi = np.array(img).flatten()  \n",
    "        data.append(numpy_dizi)\n",
    "\n",
    "sonuc_matrisi = np.vstack(data)\n",
    "\n",
    "csv_dosya_yolu = 'train_sol.csv' \n",
    "csv_matrisi = pd.read_csv(csv_dosya_yolu).values\n",
    "\n",
    "csv_matrisi = csv_matrisi[:, 1:]\n",
    "\n",
    "data_test = np.hstack((sonuc_matrisi, csv_matrisi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(11236, 100).to(device)\n",
    "        self.layer2 = nn.Linear(100, 100).to(device)\n",
    "        self.output_layer = nn.Linear(100, 37).to(device)\n",
    "        self.relu = nn.ReLU().to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "net = SimpleNeuralNetwork().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/32], Chunk Loss: 0.00061207\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.04969913\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.02866882\n",
      "Epoch [1/32], Chunk Loss: 1.06962943\n",
      "Epoch [1/32], Chunk Loss: 0.02646487\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.04710881\n",
      "Epoch [1/32], Chunk Loss: 0.02767462\n",
      "Epoch [1/32], Chunk Loss: 0.07397116\n",
      "Epoch [1/32], Chunk Loss: 0.07203469\n",
      "Epoch [1/32], Chunk Loss: 1.06302142\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 1.12480426\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.02808027\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.02487812\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.04127681\n",
      "Epoch [1/32], Chunk Loss: 0.25820068\n",
      "Epoch [1/32], Chunk Loss: 1.06133366\n",
      "Epoch [1/32], Chunk Loss: 0.06215581\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.02056027\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.05581998\n",
      "Epoch [1/32], Chunk Loss: 0.04914447\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.08725002\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.01241792\n",
      "Epoch [1/32], Chunk Loss: 0.04202737\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.04456417\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [1/32], Chunk Loss: 0.01373671\n",
      "Epoch [1/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.03616210\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.05001824\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.03312499\n",
      "Epoch [2/32], Chunk Loss: 1.04670858\n",
      "Epoch [2/32], Chunk Loss: 0.03053516\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.04729795\n",
      "Epoch [2/32], Chunk Loss: 0.02700377\n",
      "Epoch [2/32], Chunk Loss: 0.08497510\n",
      "Epoch [2/32], Chunk Loss: 0.07115033\n",
      "Epoch [2/32], Chunk Loss: 1.03396595\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 1.12588632\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.03238295\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.03344772\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.03993485\n",
      "Epoch [2/32], Chunk Loss: 0.26037294\n",
      "Epoch [2/32], Chunk Loss: 1.03403187\n",
      "Epoch [2/32], Chunk Loss: 0.05612368\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.02696296\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.05014941\n",
      "Epoch [2/32], Chunk Loss: 0.04700076\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.09971267\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.01518078\n",
      "Epoch [2/32], Chunk Loss: 0.04275174\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.04717899\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [2/32], Chunk Loss: 0.01726655\n",
      "Epoch [2/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.03486130\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.04813142\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.03621553\n",
      "Epoch [3/32], Chunk Loss: 1.02987170\n",
      "Epoch [3/32], Chunk Loss: 0.03653219\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.04546420\n",
      "Epoch [3/32], Chunk Loss: 0.02987611\n",
      "Epoch [3/32], Chunk Loss: 0.08762213\n",
      "Epoch [3/32], Chunk Loss: 0.05987441\n",
      "Epoch [3/32], Chunk Loss: 1.00699294\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 1.10394216\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.03553895\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.04152957\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.03583812\n",
      "Epoch [3/32], Chunk Loss: 0.26700798\n",
      "Epoch [3/32], Chunk Loss: 1.01888466\n",
      "Epoch [3/32], Chunk Loss: 0.05032488\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.03047222\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.04658243\n",
      "Epoch [3/32], Chunk Loss: 0.04554600\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.09869345\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.02045296\n",
      "Epoch [3/32], Chunk Loss: 0.03596459\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.05185614\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [3/32], Chunk Loss: 0.02215086\n",
      "Epoch [3/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.02992376\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.04351506\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.03796281\n",
      "Epoch [4/32], Chunk Loss: 1.02575314\n",
      "Epoch [4/32], Chunk Loss: 0.03903250\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.04299399\n",
      "Epoch [4/32], Chunk Loss: 0.03236098\n",
      "Epoch [4/32], Chunk Loss: 0.08473539\n",
      "Epoch [4/32], Chunk Loss: 0.05384983\n",
      "Epoch [4/32], Chunk Loss: 0.98839515\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 1.08323669\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.03654248\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.04213420\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.03411160\n",
      "Epoch [4/32], Chunk Loss: 0.27105567\n",
      "Epoch [4/32], Chunk Loss: 1.01995420\n",
      "Epoch [4/32], Chunk Loss: 0.04747438\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.03213516\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.04931863\n",
      "Epoch [4/32], Chunk Loss: 0.04639033\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.09399392\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.02436447\n",
      "Epoch [4/32], Chunk Loss: 0.03332461\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.05472585\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [4/32], Chunk Loss: 0.02446377\n",
      "Epoch [4/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.02810678\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.04112766\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.03790016\n",
      "Epoch [5/32], Chunk Loss: 1.02394795\n",
      "Epoch [5/32], Chunk Loss: 0.03974776\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.04141846\n",
      "Epoch [5/32], Chunk Loss: 0.03352556\n",
      "Epoch [5/32], Chunk Loss: 0.08248212\n",
      "Epoch [5/32], Chunk Loss: 0.05002197\n",
      "Epoch [5/32], Chunk Loss: 0.98644954\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 1.07261264\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.03726399\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.04126447\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.03379736\n",
      "Epoch [5/32], Chunk Loss: 0.27354822\n",
      "Epoch [5/32], Chunk Loss: 1.02509725\n",
      "Epoch [5/32], Chunk Loss: 0.04533789\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.03348561\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.05247904\n",
      "Epoch [5/32], Chunk Loss: 0.04828142\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.08915114\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.02730101\n",
      "Epoch [5/32], Chunk Loss: 0.03233038\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.05626684\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [5/32], Chunk Loss: 0.02572064\n",
      "Epoch [5/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.02747743\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.03964628\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.03747610\n",
      "Epoch [6/32], Chunk Loss: 1.02324080\n",
      "Epoch [6/32], Chunk Loss: 0.03979256\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.04114131\n",
      "Epoch [6/32], Chunk Loss: 0.03387332\n",
      "Epoch [6/32], Chunk Loss: 0.08079803\n",
      "Epoch [6/32], Chunk Loss: 0.04712030\n",
      "Epoch [6/32], Chunk Loss: 0.99045497\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 1.06790984\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.03788721\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.04063772\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.03383829\n",
      "Epoch [6/32], Chunk Loss: 0.27430651\n",
      "Epoch [6/32], Chunk Loss: 1.03097057\n",
      "Epoch [6/32], Chunk Loss: 0.04381080\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.03416073\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.05519926\n",
      "Epoch [6/32], Chunk Loss: 0.05025432\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.08590925\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.02935316\n",
      "Epoch [6/32], Chunk Loss: 0.03195460\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.05763181\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [6/32], Chunk Loss: 0.02660917\n",
      "Epoch [6/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.02722916\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.03865549\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.03673457\n",
      "Epoch [7/32], Chunk Loss: 1.02432752\n",
      "Epoch [7/32], Chunk Loss: 0.03969385\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.04057874\n",
      "Epoch [7/32], Chunk Loss: 0.03442802\n",
      "Epoch [7/32], Chunk Loss: 0.07980191\n",
      "Epoch [7/32], Chunk Loss: 0.04571500\n",
      "Epoch [7/32], Chunk Loss: 0.99389672\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 1.06602180\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.03843145\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.04008354\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.03407310\n",
      "Epoch [7/32], Chunk Loss: 0.27349985\n",
      "Epoch [7/32], Chunk Loss: 1.03408766\n",
      "Epoch [7/32], Chunk Loss: 0.04270929\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.03512130\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n",
      "Epoch [7/32], Chunk Loss: 0.05813105\n",
      "Epoch [7/32], Chunk Loss: 0.05386436\n",
      "Epoch [7/32], Chunk Loss: -0.00000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     38\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 39\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, targets\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# İleri yayılım\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m net(inputs)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_train_tensor = torch.from_numpy(data_train).float().to(device)\n",
    "\n",
    "features = data_train_tensor[:, :-37]\n",
    "labels = data_train_tensor[:, -37:]\n",
    "train_dataset = torch.utils.data.TensorDataset(features, labels)\n",
    "\n",
    "num_epochs =  32\n",
    "\n",
    "net = SimpleNeuralNetwork().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "def get_data_loader(data, batch_size, shuffle=False):\n",
    "    dataset = torch.utils.data.TensorDataset(data[:, :-37], data[:, -37:].long())\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    " \n",
    "chunk_size = 1000  \n",
    "data_chunks = [data_train_tensor[i:i + chunk_size] for i in range(0, data_train_tensor.size(0), chunk_size)]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data_chunk in data_chunks:\n",
    "        train_loader = get_data_loader(data_chunk, batch_size=16)\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device).float()\n",
    "\n",
    "            outputs = net(inputs).float()\n",
    "\n",
    "\n",
    "            loss = loss_function(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Chunk Loss: {loss.item():.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
